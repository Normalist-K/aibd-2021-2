{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using MNIST\n",
    "\n",
    "---\n",
    "\n",
    "#### Goals\n",
    "\n",
    "1. Making blocked code with well-defined flow-based functions\n",
    "2. Doing Logistic Regression on MNIST with Mini-batch Stochastic Gradient Descent\n",
    "\n",
    "---\n",
    "\n",
    "#### Basic Flow of Deep Learning\n",
    "\n",
    "![Flow Image](https://monet.postech.ac.kr/~wldh/flow.png?v=3)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Library Importation & Device Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to edit this section today.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{\"CPU\" if device == \"cpu\" else \"GPU\"} will be used in training/validation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyper-parameters\n",
    "\n",
    "By executing below blocks, you can initialize/update hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Load & Preprocessing\n",
    "\n",
    "Because MNIST dataset is already well-preprocessed imageset, we will not perform any preprocessing today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into python variable\n",
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data loader\n",
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function Definitions\n",
    "\n",
    "Because our model is too simple now, we will use just `nn.Linear` module and wrap it with initializer function instead of defining a model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    net = ### Put your script here ###\n",
    "    loss_fn = ### Put your script here ###\n",
    "    optim = ### Put your script here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "  \n",
    "def epoch(data_loader):\n",
    "    # One epoch : gets data_loader as input and returns loss / accuracy, and\n",
    "    #             last prediction value / its label(truth) value for future use\n",
    "    global epoch_cnt\n",
    "    ### Put your script here ###\n",
    "\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # For now, let's repeat training fixed times.\n",
    "    # We will learn how to determine training stop or continue later.\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "# You don't need to edit this section today.\n",
    "def init_log():\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "  \n",
    "  \n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Push time, training loss, training accuracy, and epoch count into lists\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "  \n",
    "  \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Push validation loss and validation accuracy into each list\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "  \n",
    "\n",
    "def last(log_list):\n",
    "    # Get the last member of list. If empty, return -1.\n",
    "    if len(log_list) > 0: return log_list[len(log_list) - 1]\n",
    "    else: return -1\n",
    "  \n",
    "  \n",
    "def print_log():\n",
    "    # Generate log string and put it into log stack\n",
    "    log_str = f'Iter: {last(iter_log):>4d} >> T_loss {last(tloss_log):<8.5f}   ' \\\n",
    "            + f'T_acc {last(tacc_log):<6.5f}   V_loss {last(vloss_log):<8.5f}   ' \\\n",
    "            + f'V_acc {last(vacc_log):<6.5f}   ðŸ•’ {last(time_log):5.3f}s'\n",
    "    log_stack.append(log_str)\n",
    "  \n",
    "    # Draw figure if want\n",
    "    if logging_dispfig:\n",
    "        hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99)\n",
    "        hist_fig.patch.set_facecolor('white')\n",
    "    \n",
    "        # Draw loss lines\n",
    "        loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='#FF9999', marker='o')\n",
    "        loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='#99B0FF', marker='s')\n",
    "        loss_axis.set_xlabel('epoch')\n",
    "        loss_axis.set_ylabel('loss')\n",
    "    \n",
    "        # Draw accuracy lines\n",
    "        acc_axis = loss_axis.twinx()\n",
    "        acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='#FF0000', marker='+')\n",
    "        acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='#003AFF', marker='x')\n",
    "        acc_axis.set_ylabel('accuracy')\n",
    "    \n",
    "        # Append annotations\n",
    "        hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line\n",
    "        loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines])\n",
    "        loss_axis.grid()\n",
    "        plt.title(f'Learning history until epoch {last(iter_log)}')\n",
    "        plt.draw()\n",
    "    \n",
    "    # Print log\n",
    "    clear_output(wait=True)\n",
    "    if logging_dispfig: plt.show()\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Initialization\n",
    "### Put your script here ###\n",
    "\n",
    "# Training Iteration\n",
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result Analysis\n",
    "\n",
    "In this section, we will calculate accuracy and confusion matrix for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for test dataset\n",
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "### Put your script here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving Model\n",
    "\n",
    "Are you satisfied with your model? Then save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load your model, enter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
