{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping\n",
    "\n",
    "---\n",
    "\n",
    "#### Goals\n",
    "\n",
    "1. To understand the problem of overfitting\n",
    "2. To know what countermeasures exist\n",
    "3. To implement earlystopping\n",
    "4. To compare earlystopping vs \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Library Importation & Device Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to edit this section today.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary as Summary\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, RandomHorizontalFlip, \\\n",
    "                                   Resize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{\"CPU\" if device == \"cpu\" else \"GPU\"} will be used in training/validation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyper-parameters\n",
    "\n",
    "By executing below blocks, you can initialize/update hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "input_norm_mean = (.4914, .4822, .4465)\n",
    "input_norm_std = (.2023, .1994, .2010)\n",
    "batch_size = 2000\n",
    "\n",
    "# Learning\n",
    "logging_dispfig = True\n",
    "maximum_epoch = 500\n",
    "learning_rate = 0.004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Load & Preprocessing\n",
    "\n",
    "Today we will use CIFAR-10 dataset with data augmentation.\n",
    "\n",
    "![CIFAR-10 examples](https://monet.postech.ac.kr/~wldh/CIFAR10.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into python variable\n",
    "input_transform = transforms.Compose([\n",
    "    RandomCrop(32, padding=4),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=input_norm_mean, std=input_norm_std),\n",
    "])\n",
    "\n",
    "train_data = CIFAR10(\"./\", train=True, transform=input_transform, download=True)\n",
    "train_data, valid_data = random_split(train_data, [2000, 48000])\n",
    "valid_data, trash_data = random_split(valid_data, [2000, 46000])\n",
    "test_data = CIFAR10(\"./\", train=False, transform=input_transform, download=False)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                          drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=len(valid_data), pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function Definitions\n",
    "\n",
    "Because our model is too simple now, we will use just `nn.Linear` module and wrap it with initializer function instead of defining a model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def init_model():\n",
    "    global net, best_net, loss_fn, optim\n",
    "    net = YetAnotherCNN().to(device)\n",
    "    best_net = YetAnotherCNN().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "class YetAnotherCNN(nn.Module):\n",
    "    \"\"\"My Little Convolutional Neural Network for Active CAM, based on VGG11\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(YetAnotherCNN, self).__init__()\n",
    "        self.convolution_part = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32), nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32), nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=3)\n",
    "        )\n",
    "        self.classifier_part = nn.Linear(32*5*5, 10, bias=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        conv_out = self.convolution_part(data)\n",
    "        conv_out_flatten = conv_out.reshape(conv_out.size(0), -1)\n",
    "        return self.classifier_part(conv_out_flatten)\n",
    "        #return conv_out\n",
    "\n",
    "\n",
    "# Model structure check\n",
    "Summary(YetAnotherCNN().to(device), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "def epoch(data_loader):\n",
    "    # One epoch : gets data_loader as input and returns loss / accuracy, and\n",
    "    #             last prediction value / its label(truth) value for future use\n",
    "    global epoch_cnt\n",
    "    iter_loss, iter_acc = [], []\n",
    "\n",
    "    last_grad_performed = False\n",
    "\n",
    "    # Mini-batch iterations\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.to(device)\n",
    "\n",
    "        # 1. Feed-forward\n",
    "        onehot_out = net(data)\n",
    "\n",
    "        # 2. Calculate accuracy\n",
    "        _, out = torch.max(onehot_out, 1)\n",
    "        acc_partial = (out == label).float().sum()\n",
    "        acc_partial = acc_partial / len(label)\n",
    "        iter_acc.append(acc_partial.item())\n",
    "\n",
    "        # 3. Calculate loss\n",
    "        loss = loss_fn(onehot_out, label)\n",
    "        iter_loss.append(loss.item())\n",
    "\n",
    "        # 4. Backward propagation if not in `torch.no_grad()`\n",
    "        if onehot_out.requires_grad:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            last_grad_performed = True\n",
    "\n",
    "    # Up epoch count if backward propagation is done\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    \n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # For now, let's repeat training fixed times, e.g. 25 times.\n",
    "    # We will learn how to determine training stop or continue later.\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlystopping\n",
    "def copy_weights(src, dst):\n",
    "    dst.load_state_dict(src.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "def init_log():\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "\n",
    "\n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Push time, training loss, training accuracy, and epoch count into lists\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "\n",
    "\n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Push validation loss and validation accuracy into each list\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "\n",
    "def last(log_list):\n",
    "    # Get the last member of list. If empty, return -1.\n",
    "    if len(log_list) > 0: return log_list[len(log_list) - 1]\n",
    "    else: return -1\n",
    "\n",
    "\n",
    "def print_log():\n",
    "    # Generate log string and put it into log stack\n",
    "    log_str = f'Iter: {last(iter_log):>4d} >> T_loss {last(tloss_log):<8.5f}   ' \\\n",
    "            + f'T_acc {last(tacc_log):<6.5f}   V_loss {last(vloss_log):<8.5f}   ' \\\n",
    "            + f'V_acc {last(vacc_log):<6.5f}   ðŸ•’ {last(time_log):5.3f}s'\n",
    "    if earlystop_cnt > 0:\n",
    "        log_str += f' | es_cnt = {earlystop_cnt}'\n",
    "    log_stack.append(log_str)\n",
    "  \n",
    "    # Draw figure if want\n",
    "    if logging_dispfig:\n",
    "        hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99)\n",
    "        hist_fig.patch.set_facecolor('white')\n",
    "\n",
    "        # Draw loss lines\n",
    "        loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='#FF9999', marker='o')\n",
    "        loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='#99B0FF', marker='s')\n",
    "        loss_axis.set_xlabel('epoch')\n",
    "        loss_axis.set_ylabel('loss')\n",
    "\n",
    "        # Draw accuracy lines\n",
    "        acc_axis = loss_axis.twinx()\n",
    "        acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='#FF0000', marker='+')\n",
    "        acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='#003AFF', marker='x')\n",
    "        acc_axis.set_ylabel('accuracy')\n",
    "\n",
    "        # Append annotations\n",
    "        hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line\n",
    "        loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines])\n",
    "        loss_axis.grid()\n",
    "        plt.title(f'Learning history until epoch {last(iter_log)}')\n",
    "        plt.draw()\n",
    "\n",
    "    # Print log\n",
    "    clear_output(wait=True)\n",
    "    if logging_dispfig: plt.show()\n",
    "    if earlystop_cnt > 0:\n",
    "        print(f'Current earlystop count = {earlystop_cnt} / {earlystop_patience}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Initialization\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "\n",
    "# Training Iteration\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader)\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(valid_loader)\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed\\n')\n",
    "for idx in reversed(range(len(log_stack))):\n",
    "    print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result Analysis\n",
    "\n",
    "In this section, we will calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for test dataset\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader)\n",
    "    print(f'Test accuracy = {test_acc}\\nTest loss = {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving Model\n",
    "\n",
    "Are you satisfied with your model? Then save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load your model, enter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
