{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "  <img style=\"padding-bottom: 14px\" src=\"https://monet.postech.ac.kr/~wldh/CNN.png\" alt=\"CNN Logo\" />\n",
    "  <br />\n",
    "  Convolutional Neural Network (CNN)\n",
    "</h1>\n",
    "\n",
    "---\n",
    "\n",
    "#### Goals\n",
    "\n",
    "1. Augment(Preprocess) your data\n",
    "2. Implement a CNN model\n",
    "3. Learn CIFAR-10 using your CNN model\n",
    "4. View the features (Active CAM)\n",
    "5. Understand the overfitting\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Library Importation & Device Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to edit this section today.\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from skimage.transform import resize as OVResize\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary as Summary\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, RandomHorizontalFlip, \\\n",
    "                                   ToPILImage, Resize, Grayscale\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{\"CPU\" if device == \"cpu\" else \"GPU\"} will be used in training/validation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyper-parameters\n",
    "\n",
    "By executing below blocks, you can initialize/update hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "input_norm_mean = (.4914, .4822, .4465)\n",
    "input_norm_std = (.2023, .1994, .2010)\n",
    "batch_size = 16\n",
    "\n",
    "# Learning\n",
    "logging_dispfig = True\n",
    "maximum_epoch = 15\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Load & Preprocessing\n",
    "\n",
    "Today we will use CIFAR-10 dataset with data augmentation.\n",
    "\n",
    "![CIFAR-10 examples](https://monet.postech.ac.kr/~wldh/CIFAR10.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into python variable\n",
    "input_transform = transforms.Compose([\n",
    "  ### Put your script here ###\n",
    "])\n",
    "\n",
    "train_data = CIFAR10(\"./\", train=True, transform=input_transform, download=True)\n",
    "train_data, valid_data = random_split(train_data, [45000, 5000])\n",
    "test_data = CIFAR10(\"./\", train=False, transform=input_transform, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "print(f'Train dataset length = {len(train_data)}')\n",
    "print(f'Valid dataset length = {len(valid_data)}')\n",
    "print(f'Test dataset length = {len(test_data)}\\n')\n",
    "\n",
    "print(f'Classes = {test_data.classes}\\n')\n",
    "\n",
    "train_0_x, train_0_y = train_data[0]\n",
    "print(f'Label ({type(train_0_y).__name__}) = {train_0_y} ({test_data.classes[train_0_y]})')\n",
    "print(f'Data ({type(train_0_x).__name__}) = {train_0_x.shape}\\n')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.suptitle(f'Example data 0 [label={test_data.classes[train_0_y]}]')\n",
    "ax1.imshow(train_0_x[0, :, :])\n",
    "ax1.set_title('Ch. 0 (Red)')\n",
    "ax2.imshow(train_0_x[1, :, :])\n",
    "ax2.set_title('Ch. 1 (Green)')\n",
    "ax3.imshow(train_0_x[2, :, :])\n",
    "ax3.set_title('Ch. 2 (Blue)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader (same with day 2)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                          drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data loader\n",
    "train_enumerator = enumerate(train_loader)\n",
    "ex_batch_idx, (ex_data, ex_label) = next(train_enumerator)\n",
    "print(f'Idx: {ex_batch_idx} / X.shape = {ex_data.shape} / Y.shape = {ex_label.shape}\\n')\n",
    "print(f'Y[0:{batch_size}] = {ex_label.tolist()}')\n",
    "print(f'â†’ Label = {np.array(test_data.classes)[ex_label]}\\n')\n",
    "\n",
    "preview_index = 1\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.suptitle(f'Example data {preview_index} from DataLoader [label={test_data.classes[ex_label[preview_index]]}]')\n",
    "ax1.imshow(ex_data[preview_index, 0, :, :])\n",
    "ax1.set_title('Ch. 0 (Red)')\n",
    "ax2.imshow(ex_data[preview_index, 1, :, :])\n",
    "ax2.set_title('Ch. 1 (Green)')\n",
    "ax3.imshow(ex_data[preview_index, 2, :, :])\n",
    "ax3.set_title('Ch. 2 (Blue)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function Definitions\n",
    "\n",
    "Because our model is too simple now, we will use just `nn.Linear` module and wrap it with initializer function instead of defining a model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    ### Put your script here ###\n",
    "\n",
    "    \n",
    "class MyLittleCNN(nn.Module):\n",
    "    \"\"\"My Little Convolutional Neural Network for Active CAM, based on VGG11\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyLittleCNN, self).__init__()\n",
    "        ### Put your script here ###\n",
    "\n",
    "    def forward(self, data):\n",
    "        ### Put your script here ###\n",
    "\n",
    "\n",
    "# Model structure check\n",
    "Summary(MyLittleCNN().to(device), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory cleaner to prevent CUDA out of memory error\n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch (similar to day 2)\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "\n",
    "def epoch(data_loader):\n",
    "    # One epoch : gets data_loader as input and returns loss / accuracy, and\n",
    "    #             last prediction value / its label(truth) value for future use\n",
    "    global epoch_cnt\n",
    "    iter_loss, iter_acc = [], []\n",
    "\n",
    "    last_grad_performed = False\n",
    "\n",
    "    # Mini-batch iterations\n",
    "    for _data, _label in data_loader:\n",
    "    data, label = _data.to(device), _label.to(device)\n",
    "\n",
    "    # 1. Feed-forward\n",
    "    onehot_out, _ = net(data)\n",
    "\n",
    "    # 2. Calculate accuracy\n",
    "    _, out = torch.max(onehot_out, 1)\n",
    "    acc_partial = (out == label).float().sum()\n",
    "    acc_partial = acc_partial / len(label)\n",
    "    iter_acc.append(acc_partial.item())\n",
    "\n",
    "    # 3. Calculate loss\n",
    "    loss = loss_fn(onehot_out, label)\n",
    "    iter_loss.append(loss.item())\n",
    "\n",
    "    # 4. Backward propagation if not in `torch.no_grad()`\n",
    "    if onehot_out.requires_grad:\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        last_grad_performed = True\n",
    "\n",
    "    # Up epoch count if backward propagation is done\n",
    "    if last_grad_performed:\n",
    "    epoch_cnt += 1\n",
    "\n",
    "    # Clear memory to prevent CUDA memory error\n",
    "    clear_memory()\n",
    "\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # For now, let's repeat training fixed times, e.g. 25 times.\n",
    "    # We will learn how to determine training stop or continue later.\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging (same with day 2)\n",
    "def init_log():\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "\n",
    "\n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Push time, training loss, training accuracy, and epoch count into lists\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "\n",
    "\n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Push validation loss and validation accuracy into each list\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "\n",
    "def last(log_list):\n",
    "    # Get the last member of list. If empty, return -1.\n",
    "    if len(log_list) > 0: return log_list[len(log_list) - 1]\n",
    "    else: return -1\n",
    "\n",
    "\n",
    "def print_log():\n",
    "    # Generate log string and put it into log stack\n",
    "    log_str = f'Iter: {last(iter_log):>4d} >> T_loss {last(tloss_log):<8.5f}   ' \\\n",
    "            + f'T_acc {last(tacc_log):<6.5f}   V_loss {last(vloss_log):<8.5f}   ' \\\n",
    "            + f'V_acc {last(vacc_log):<6.5f}   ðŸ•’ {last(time_log):5.3f}s'\n",
    "    log_stack.append(log_str)\n",
    "\n",
    "    # Draw figure if want\n",
    "    if logging_dispfig:\n",
    "        hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99)\n",
    "        hist_fig.patch.set_facecolor('white')\n",
    "\n",
    "        # Draw loss lines\n",
    "        loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='#FF9999', marker='o')\n",
    "        loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='#99B0FF', marker='s')\n",
    "        loss_axis.set_xlabel('epoch')\n",
    "        loss_axis.set_ylabel('loss')\n",
    "\n",
    "        # Draw accuracy lines\n",
    "        acc_axis = loss_axis.twinx()\n",
    "        acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='#FF0000', marker='+')\n",
    "        acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='#003AFF', marker='x')\n",
    "        acc_axis.set_ylabel('accuracy')\n",
    "\n",
    "        # Append annotations\n",
    "        hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line\n",
    "        loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines])\n",
    "        loss_axis.grid()\n",
    "        plt.title(f'Learning history until epoch {last(iter_log)}')\n",
    "        plt.draw()\n",
    "\n",
    "    # Print log\n",
    "    clear_output(wait=True)\n",
    "    if logging_dispfig: plt.show()\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Initialization (same with day 2)\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "\n",
    "# Training Iteration (similar to day 2)\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader)\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(valid_loader)\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "    \n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result Analysis\n",
    "\n",
    "In this section, we will calculate accuracy and confusion matrix for test dataset.\n",
    "\n",
    "### 6.A Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for test dataset (similar to day 2)\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader)\n",
    "    print(f'Test accuracy = {test_acc}\\nTest loss = {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B Class Activiation Map (CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation (load test data again, but without data augmentation)\n",
    "cam_data_iterable = CIFAR10(root='./', train=False, download=False)\n",
    "cam_data = list(cam_data_iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw CAMs\n",
    "cam_figidx = 1\n",
    "cam_random_order = np.arange(len(cam_data), dtype=int)\n",
    "np.random.shuffle(cam_random_order)\n",
    "\n",
    "fig = plt.figure(figsize=(23, 47))\n",
    "for class_idx, class_label in enumerate(cam_data_iterable.classes):\n",
    "    # We will draw 5 CAMs for each classes\n",
    "    class_axes = [\n",
    "    fig.add_subplot(10, 5, cam_figidx),\n",
    "    fig.add_subplot(10, 5, cam_figidx + 1),\n",
    "    fig.add_subplot(10, 5, cam_figidx + 2),\n",
    "    fig.add_subplot(10, 5, cam_figidx + 3),\n",
    "    fig.add_subplot(10, 5, cam_figidx + 4)\n",
    "    ]\n",
    "    cam_figidx = cam_figidx + 5\n",
    "\n",
    "    # Find 5 proper data with a specified \"label\"\n",
    "    class_figidx = 0\n",
    "    for random_order in cam_random_order:\n",
    "        data, label = cam_data[random_order]\n",
    "        if label == class_idx:\n",
    "            # 1. Preprocess original image to put it into the model\n",
    "            temp_input = ToTensor()(Resize(224)(data))\n",
    "            temp_input = Normalize(mean=input_norm_mean, std=input_norm_std)(temp_input)\n",
    "            temp_input = temp_input.reshape((1, 3, 224, 224)).to(device)\n",
    "      \n",
    "            # 2. Put the data into model and get convolutional part output and classifier output\n",
    "            with torch.no_grad():\n",
    "                temp_classifier_out, temp_conv_out = net(temp_input)\n",
    "                _, temp_predicted_class = torch.max(temp_classifier_out, 1)\n",
    "      \n",
    "            # 3. If the predicted label is same with the truth, draw CAM of it\n",
    "            if temp_predicted_class == label:\n",
    "                conv_class_weight = list(net.parameters())[-1].squeeze()[label]\n",
    "                temp_conv_out = temp_conv_out.reshape(512, 49)\n",
    "                cam = conv_class_weight.matmul(temp_conv_out).reshape(7, 7).cpu().data.numpy()\n",
    "                cam = cam - np.min(cam)\n",
    "                cam = cam / np.max(cam)\n",
    "                class_axes[class_figidx].imshow(\n",
    "                  Grayscale()(Resize((512, 512), interpolation=0)(data)),\n",
    "                  cmap='gray',\n",
    "                )\n",
    "                class_axes[class_figidx].imshow(OVResize(cam, [512, 512]), cmap='jet', alpha=0.4)\n",
    "                class_axes[class_figidx].set_xticks([], minor=False)\n",
    "                class_axes[class_figidx].set_yticks([], minor=False)\n",
    "                if class_figidx == 2:\n",
    "                    class_axes[class_figidx].set_title(f'\\n============ [ {class_label} ] ============\\n')\n",
    "                class_figidx = class_figidx + 1\n",
    "                if class_figidx >= 5:\n",
    "                    break\n",
    "  \n",
    "    # Tiny error message\n",
    "    if class_figidx != 5:\n",
    "        print(f'Failed to find proper data for {class_label}[{class_idx}].')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving Model\n",
    "\n",
    "Are you satisfied with your model? Then save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load your model, enter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
